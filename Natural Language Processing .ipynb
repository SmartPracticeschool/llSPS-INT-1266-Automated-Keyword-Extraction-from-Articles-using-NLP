{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VwK5-9FIB-lu"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\teja\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\teja\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\teja\\anaconda3\\lib\\site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\teja\\anaconda3\\lib\\site-packages (1.18.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\teja\\anaconda3\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\teja\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pandas in c:\\users\\teja\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\teja\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\teja\\anaconda3\\lib\\site-packages (from nltk) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\teja\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\teja\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\teja\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1kiO9kACE6s"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QG7sxmoCIvN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTfaCIzdCLPA"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCK6vQ5QCQJe"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qekztq71CixT"
   },
   "source": [
    "## Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3342,
     "status": "ok",
     "timestamp": 1586421521761,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "8u_yXh9dCmEE",
    "outputId": "59406636-e0c4-4547-c918-42ae30c11642"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jawahar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLqmAkANCp1-"
   },
   "source": [
    "## Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qroF7XcSCvY3"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH_VjgPzC2cd"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQXYM5VzDDDI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VkIq23vEDIPt"
   },
   "source": [
    "## Training the Naive Bayes model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1586421527177,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "DS9oiDXXDRdI",
    "outputId": "e4c2c831-e9dd-45f5-a23b-dd70f59cedfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "print(X_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JaRM7zXDWUy"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iif0CVhFDaMp"
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0\n",
      " 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0\n",
      " 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoMltea5Dir1"
   },
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 42]\n",
      " [12 91]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy using Naive Bayes model --  0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Model accuracy using Naive Bayes model -- \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jawahar/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The service was great, even the manager came and helped with our table.\n",
      "[ 1 17  4 22 90  1 78  2 21 41]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\n",
    "#df.columns = [\"label\",\"text\"]\n",
    "x = df['Review'].values\n",
    "y = df['Liked'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    " train_test_split(x, y, test_size=0.1, random_state=123)\n",
    "#print(x_test)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(x)\n",
    "xtrain= tokenizer.texts_to_sequences(x_train)\n",
    "xtest= tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "\n",
    "maxlen=10\n",
    "xtrain=pad_sequences(xtrain,padding='post', maxlen=maxlen)\n",
    "xtest=pad_sequences(xtest,padding='post', maxlen=maxlen) \n",
    " \n",
    "print(x_train[3])\n",
    "print(xtrain[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jawahar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jawahar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jawahar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jawahar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jawahar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jawahar/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jawahar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jawahar/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 50)            103600    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10)                2440      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 126,337\n",
      "Trainable params: 126,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=50\n",
    "\n",
    "model=Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(layers.LSTM(units=50,return_sequences=True))\n",
    "model.add(layers.LSTM(units=10))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "900/900 [==============================] - 7s 8ms/step - loss: 0.6929 - acc: 0.5044\n",
      "Epoch 2/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.6888 - acc: 0.5278\n",
      "Epoch 3/100\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.6049 - acc: 0.6933\n",
      "Epoch 4/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.5388 - acc: 0.7367\n",
      "Epoch 5/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.5085 - acc: 0.7656\n",
      "Epoch 6/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4819 - acc: 0.7789\n",
      "Epoch 7/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4659 - acc: 0.7733\n",
      "Epoch 8/100\n",
      "900/900 [==============================] - 1s 996us/step - loss: 0.4804 - acc: 0.7611\n",
      "Epoch 9/100\n",
      "900/900 [==============================] - 1s 983us/step - loss: 0.4575 - acc: 0.7844\n",
      "Epoch 10/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4744 - acc: 0.7733\n",
      "Epoch 11/100\n",
      "900/900 [==============================] - 1s 984us/step - loss: 0.4577 - acc: 0.7800\n",
      "Epoch 12/100\n",
      "900/900 [==============================] - 1s 970us/step - loss: 0.4614 - acc: 0.7822\n",
      "Epoch 13/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4532 - acc: 0.7900\n",
      "Epoch 14/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4445 - acc: 0.7811\n",
      "Epoch 15/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4488 - acc: 0.7933\n",
      "Epoch 16/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4276 - acc: 0.7911\n",
      "Epoch 17/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4368 - acc: 0.7822\n",
      "Epoch 18/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4216 - acc: 0.7944\n",
      "Epoch 19/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4355 - acc: 0.7711\n",
      "Epoch 20/100\n",
      "900/900 [==============================] - 1s 980us/step - loss: 0.4039 - acc: 0.7889\n",
      "Epoch 21/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4076 - acc: 0.7933\n",
      "Epoch 22/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4006 - acc: 0.7989\n",
      "Epoch 23/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.4058 - acc: 0.7889\n",
      "Epoch 24/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3788 - acc: 0.8100\n",
      "Epoch 25/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3591 - acc: 0.8122\n",
      "Epoch 26/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3789 - acc: 0.8133\n",
      "Epoch 27/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3637 - acc: 0.8189\n",
      "Epoch 28/100\n",
      "900/900 [==============================] - 1s 979us/step - loss: 0.3679 - acc: 0.8089\n",
      "Epoch 29/100\n",
      "900/900 [==============================] - 1s 996us/step - loss: 0.3971 - acc: 0.8122\n",
      "Epoch 30/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3804 - acc: 0.7889\n",
      "Epoch 31/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3865 - acc: 0.8111\n",
      "Epoch 32/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3540 - acc: 0.8033\n",
      "Epoch 33/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3568 - acc: 0.8167\n",
      "Epoch 34/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3315 - acc: 0.8256\n",
      "Epoch 35/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3177 - acc: 0.8378\n",
      "Epoch 36/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3136 - acc: 0.8400\n",
      "Epoch 37/100\n",
      "900/900 [==============================] - 1s 999us/step - loss: 0.3132 - acc: 0.8411\n",
      "Epoch 38/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3445 - acc: 0.8311\n",
      "Epoch 39/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3234 - acc: 0.8300\n",
      "Epoch 40/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3026 - acc: 0.8467\n",
      "Epoch 41/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2917 - acc: 0.8500\n",
      "Epoch 42/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2883 - acc: 0.8444\n",
      "Epoch 43/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.2724 - acc: 0.8544\n",
      "Epoch 44/100\n",
      "900/900 [==============================] - 2s 3ms/step - loss: 0.3430 - acc: 0.8233\n",
      "Epoch 45/100\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.3239 - acc: 0.8444\n",
      "Epoch 46/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.2929 - acc: 0.8422\n",
      "Epoch 47/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.2747 - acc: 0.8556\n",
      "Epoch 48/100\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.2536 - acc: 0.8533\n",
      "Epoch 49/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2458 - acc: 0.8678\n",
      "Epoch 50/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2303 - acc: 0.8800\n",
      "Epoch 51/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.2396 - acc: 0.8800\n",
      "Epoch 52/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2214 - acc: 0.8789\n",
      "Epoch 53/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.2254 - acc: 0.8856\n",
      "Epoch 54/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2375 - acc: 0.8789\n",
      "Epoch 55/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2332 - acc: 0.8844\n",
      "Epoch 56/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3155 - acc: 0.8411\n",
      "Epoch 57/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2944 - acc: 0.8378\n",
      "Epoch 58/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2598 - acc: 0.8644\n",
      "Epoch 59/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2366 - acc: 0.8856\n",
      "Epoch 60/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2176 - acc: 0.8856\n",
      "Epoch 61/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2140 - acc: 0.8922\n",
      "Epoch 62/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2024 - acc: 0.9056\n",
      "Epoch 63/100\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.2079 - acc: 0.8978\n",
      "Epoch 64/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1882 - acc: 0.8978\n",
      "Epoch 65/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2561 - acc: 0.8744\n",
      "Epoch 66/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2427 - acc: 0.8756\n",
      "Epoch 67/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.2159 - acc: 0.8867\n",
      "Epoch 68/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1969 - acc: 0.9044\n",
      "Epoch 69/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1778 - acc: 0.9033\n",
      "Epoch 70/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1848 - acc: 0.9133\n",
      "Epoch 71/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1724 - acc: 0.9200\n",
      "Epoch 72/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1695 - acc: 0.9156\n",
      "Epoch 73/100\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1740 - acc: 0.9044\n",
      "Epoch 74/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.2052 - acc: 0.8956\n",
      "Epoch 75/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1947 - acc: 0.9011\n",
      "Epoch 76/100\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1895 - acc: 0.9056\n",
      "Epoch 77/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2105 - acc: 0.8922\n",
      "Epoch 78/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1842 - acc: 0.9033\n",
      "Epoch 79/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1849 - acc: 0.9144\n",
      "Epoch 80/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1826 - acc: 0.9100\n",
      "Epoch 81/100\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1646 - acc: 0.9233\n",
      "Epoch 82/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1495 - acc: 0.9267\n",
      "Epoch 83/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1405 - acc: 0.9311\n",
      "Epoch 84/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1411 - acc: 0.9211\n",
      "Epoch 85/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1378 - acc: 0.9322\n",
      "Epoch 86/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1407 - acc: 0.9278\n",
      "Epoch 87/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3360 - acc: 0.8722\n",
      "Epoch 88/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2864 - acc: 0.8700\n",
      "Epoch 89/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2014 - acc: 0.9000\n",
      "Epoch 90/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1705 - acc: 0.9078\n",
      "Epoch 91/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1546 - acc: 0.9200\n",
      "Epoch 92/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1495 - acc: 0.9211\n",
      "Epoch 93/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1474 - acc: 0.9189\n",
      "Epoch 94/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1380 - acc: 0.9300\n",
      "Epoch 95/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1361 - acc: 0.9233\n",
      "Epoch 96/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1298 - acc: 0.9322\n",
      "Epoch 97/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1331 - acc: 0.9344\n",
      "Epoch 98/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1287 - acc: 0.9367\n",
      "Epoch 99/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1222 - acc: 0.9344\n",
      "Epoch 100/100\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1256 - acc: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae451bda90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,y_train, epochs=100, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model predicions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8\n",
      "Test Accuracy:  0.7\n",
      "[[37  8]\n",
      " [22 33]]\n",
      "('Penne vodka excellent!', 1, array([0.], dtype=float32))\n",
      "('Great brunch spot.', 1, array([1.], dtype=float32))\n",
      "('We ordered the duck rare and it was pink and tender on the inside with a nice char on the outside.', 1, array([1.], dtype=float32))\n",
      "('Great food and great service in a clean and friendly setting.', 1, array([1.], dtype=float32))\n",
      "('He was extremely rude and really, there are so many other restaurants I would love to dine at during a weekend in Vegas.', 0, array([1.], dtype=float32))\n",
      "('Same evening, him and I are both drastically sick.', 0, array([0.], dtype=float32))\n",
      "(\"I go to far too many places and I've never seen any restaurant that serves a 1 egg breakfast, especially for $4.00.\", 0, array([0.], dtype=float32))\n",
      "('The vanilla ice cream was creamy and smooth while the profiterole (choux) pastry was fresh enough.', 1, array([0.], dtype=float32))\n",
      "('However, there was so much garlic in the fondue, it was barely edible.', 0, array([0.], dtype=float32))\n",
      "('I LOVED it!', 1, array([0.], dtype=float32))\n",
      "('The best place to go for a tasty bowl of Pho!', 1, array([1.], dtype=float32))\n",
      "('The service was a bit lacking.', 0, array([0.], dtype=float32))\n",
      "('The sides are delish - mixed mushrooms, yukon gold puree, white corn - beateous.', 1, array([0.], dtype=float32))\n",
      "('RUDE & INCONSIDERATE MANAGEMENT.', 0, array([0.], dtype=float32))\n",
      "('this was a different cut than the piece the other day but still wonderful and tender s well as well flavored.', 1, array([0.], dtype=float32))\n",
      "('They could serve it with just the vinaigrette and it may make for a better overall dish, but it was still very good.', 1, array([0.], dtype=float32))\n",
      "('The place was not clean and the food oh so stale!', 0, array([0.], dtype=float32))\n",
      "('The only downside is the service.', 0, array([1.], dtype=float32))\n",
      "('The chefs were friendly and did a good job.', 1, array([1.], dtype=float32))\n",
      "('I really enjoyed eating here.', 1, array([0.], dtype=float32))\n",
      "('The dining space is tiny, but elegantly decorated and comfortable.', 1, array([0.], dtype=float32))\n",
      "('The food was excellent and service was very good.', 1, array([1.], dtype=float32))\n",
      "('This is the place where I first had pho and it was amazing!!', 1, array([1.], dtype=float32))\n",
      "('The pizza selections are good.', 1, array([1.], dtype=float32))\n",
      "('It was a pale color instead of nice and char and has NO flavor.', 0, array([0.], dtype=float32))\n",
      "('It sure does beat the nachos at the movies but I would expect a little bit more coming from a restaurant.', 0, array([0.], dtype=float32))\n",
      "(\"Friend's pasta -- also bad, he barely touched it.\", 0, array([0.], dtype=float32))\n",
      "('I love the Pho and the spring rolls oh so yummy you have to try.', 1, array([1.], dtype=float32))\n",
      "('We definately enjoyed ourselves.', 1, array([0.], dtype=float32))\n",
      "('The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.', 0, array([1.], dtype=float32))\n",
      "('The food was great as always, compliments to the chef.', 1, array([1.], dtype=float32))\n",
      "('On a positive note, our server was very attentive and provided great service.', 1, array([1.], dtype=float32))\n",
      "('The servers went back and forth several times, not even so much as an \"Are you being helped?\"', 0, array([0.], dtype=float32))\n",
      "('Back to good BBQ, lighter fare, reasonable pricing and tell the public they are back to the old ways.', 1, array([1.], dtype=float32))\n",
      "('Weird vibe from owners.', 0, array([0.], dtype=float32))\n",
      "('When I opened the sandwich, I was impressed, but not in a good way.', 0, array([0.], dtype=float32))\n",
      "(\"It shouldn't take 30 min for pancakes and eggs.\", 0, array([0.], dtype=float32))\n",
      "('The bathrooms are clean and the place itself is well decorated.', 1, array([1.], dtype=float32))\n",
      "('This place is like Chipotle, but BETTER.', 1, array([0.], dtype=float32))\n",
      "('Great place fo take out or eat in.', 1, array([1.], dtype=float32))\n",
      "('Great time - family dinner on a Sunday night.', 1, array([1.], dtype=float32))\n",
      "('First - the bathrooms at this location were dirty- Seat covers were not replenished & just plain yucky!!!', 0, array([0.], dtype=float32))\n",
      "('High-quality chicken on the chicken Caesar salad.', 1, array([0.], dtype=float32))\n",
      "('Fantastic food!', 1, array([0.], dtype=float32))\n",
      "('The sergeant pepper beef sandwich with auju sauce is an excellent sandwich as well.', 1, array([1.], dtype=float32))\n",
      "(\"I probably won't be back, to be honest.\", 0, array([0.], dtype=float32))\n",
      "('OMG, the food was delicioso!', 1, array([0.], dtype=float32))\n",
      "('Their regular toasted bread was equally satisfying with the occasional pats of butter... Mmmm...!', 1, array([1.], dtype=float32))\n",
      "(\"And considering the two of us left there very full and happy for about $20, you just can't go wrong.\", 1, array([0.], dtype=float32))\n",
      "('Everyone is treated equally special.', 1, array([0.], dtype=float32))\n",
      "('I was seated immediately.', 1, array([0.], dtype=float32))\n",
      "('The yellowtail carpaccio was melt in your mouth fresh.', 1, array([0.], dtype=float32))\n",
      "('We will not be coming back.', 0, array([0.], dtype=float32))\n",
      "('I got food poisoning here at the buffet.', 0, array([0.], dtype=float32))\n",
      "('This place deserves one star and 90% has to do with the food.', 0, array([1.], dtype=float32))\n",
      "('The live music on Fridays totally blows.', 0, array([0.], dtype=float32))\n",
      "('Great food.', 1, array([1.], dtype=float32))\n",
      "(\"So don't go there if you are looking for good food...\", 0, array([0.], dtype=float32))\n",
      "(\"It'll be a regular stop on my trips to Phoenix!\", 1, array([0.], dtype=float32))\n",
      "('I have been here several times in the past, and the experience has always been great.', 1, array([1.], dtype=float32))\n",
      "('This place was such a nice surprise!', 1, array([1.], dtype=float32))\n",
      "('If there were zero stars I would give it zero stars.', 0, array([0.], dtype=float32))\n",
      "('The waitresses are very friendly.', 1, array([1.], dtype=float32))\n",
      "('Do yourself a favor and stay away from this dish.', 0, array([0.], dtype=float32))\n",
      "('I dressed up to be treated so rudely!', 0, array([0.], dtype=float32))\n",
      "('Have been going since 2007 and every meal has been awesome!!', 1, array([0.], dtype=float32))\n",
      "(\"The chains, which I'm no fan of, beat this place easily.\", 0, array([0.], dtype=float32))\n",
      "('Sorry, I will not be getting food from here anytime soon :(', 0, array([0.], dtype=float32))\n",
      "(\"It's NOT hard to make a decent hamburger.\", 0, array([0.], dtype=float32))\n",
      "('This really is how Vegas fine dining used to be, right down to the menus handed to the ladies that have no prices listed.', 1, array([0.], dtype=float32))\n",
      "('Pretty good beer selection too.', 1, array([1.], dtype=float32))\n",
      "('I love that they put their food in nice plastic containers as opposed to cramming it in little paper takeout boxes.', 1, array([1.], dtype=float32))\n",
      "('Go To Place for Gyros.', 1, array([0.], dtype=float32))\n",
      "('The service was a little slow , considering that were served by 3 people servers so the food was coming in a slow pace.', 0, array([1.], dtype=float32))\n",
      "('The desserts were a bit strange.', 0, array([0.], dtype=float32))\n",
      "('Our waiter was very attentive, friendly, and informative.', 1, array([1.], dtype=float32))\n",
      "(\"The ambiance isn't much better.\", 0, array([0.], dtype=float32))\n",
      "(\"The place was fairly clean but the food simply wasn't worth it.\", 0, array([0.], dtype=float32))\n",
      "('Love this place, hits the spot when I want something healthy but not lacking in quantity or flavor.', 1, array([1.], dtype=float32))\n",
      "('I just wanted to leave.', 0, array([1.], dtype=float32))\n",
      "(\"I like Steiners because it's dark and it feels like a bar.\", 1, array([0.], dtype=float32))\n",
      "('The service was not up to par, either.', 0, array([0.], dtype=float32))\n",
      "('Lastly, the mozzarella sticks, they were the best thing we ordered.', 1, array([1.], dtype=float32))\n",
      "('Sauce was tasteless.', 0, array([0.], dtype=float32))\n",
      "(\"If you are reading this please don't go there.\", 0, array([0.], dtype=float32))\n",
      "('Good prices.', 1, array([1.], dtype=float32))\n",
      "('Hands down my favorite Italian restaurant!', 1, array([1.], dtype=float32))\n",
      "('The problem I have is that they charge $11.99 for a sandwich that is no bigger than a Subway sub (which offers better and more amount of vegetables).', 0, array([0.], dtype=float32))\n",
      "(\"This is some seriously good pizza and I'm an expert/connisseur on the topic.\", 1, array([1.], dtype=float32))\n",
      "('Now I am getting angry and I want my damn pho.', 0, array([0.], dtype=float32))\n",
      "('The Macarons here are insanely good.', 1, array([1.], dtype=float32))\n",
      "('Shrimp- When I unwrapped it (I live only 1/2 a mile from Brushfire) it was literally ice cold.', 0, array([0.], dtype=float32))\n",
      "('WAAAAAAyyyyyyyyyy over rated is all I am saying.', 0, array([1.], dtype=float32))\n",
      "('There is not a deal good enough that would drag me into that establishment again.', 0, array([0.], dtype=float32))\n",
      "('Delicious NYC bagels, good selections of cream cheese, real Lox with capers even.', 1, array([1.], dtype=float32))\n",
      "('The meat was pretty dry, I had the sliced brisket and pulled pork.', 0, array([1.], dtype=float32))\n",
      "('I love this place.', 1, array([1.], dtype=float32))\n",
      "(\"I can't tell you how disappointed I was.\", 0, array([0.], dtype=float32))\n",
      "('I had high hopes for this place since the burgers are cooked over a charcoal grill, but unfortunately the taste fell flat, way flat.', 0, array([0.], dtype=float32))\n",
      "('All of the tapas dishes were delicious!', 1, array([1.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(xtrain, y_train, verbose=False)\n",
    "print(\"Training Accuracy: \", acc.round(2))\n",
    "loss, acc = model.evaluate(xtest, y_test, verbose=False)\n",
    "print(\"Test Accuracy: \", acc.round(2))\n",
    "\n",
    "ypred=model.predict(xtest)\n",
    "\n",
    "ypred[ypred>0.5]=1 \n",
    "ypred[ypred<=0.5]=0 \n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "print(cm)\n",
    "\n",
    "result=zip(x_test, y_test, ypred)\n",
    "\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicitions for new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review_class(review: str):\n",
    "    tokenizer = Tokenizer(num_words=100)\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    review_seq= tokenizer.texts_to_sequences([review])\n",
    "    vocab_size=len(tokenizer.word_index)+1\n",
    "    maxlen=10\n",
    "    review_seq=pad_sequences(review_seq,padding='post', maxlen=maxlen) \n",
    "    result = model.predict_classes(review_seq)\n",
    "    if result == 1:\n",
    "        print(\"Good review, well done.\")\n",
    "    else:\n",
    "        print(\"Bad review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good review, well done.\n"
     ]
    }
   ],
   "source": [
    "predict_review_class(\"this is so cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM9tx3HllsdwqqTLZQw/zx5",
   "collapsed_sections": [],
   "name": "Natural Language Processing",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
